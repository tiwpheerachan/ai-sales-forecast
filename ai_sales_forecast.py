import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import openai
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.preprocessing import LabelEncoder
from datetime import datetime
import calendar
import os

st.set_page_config(page_title="üìä AI Sales & Product Forecasting", layout="wide")

# Set OpenAI API Key securely
openai.api_key = st.secrets["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"]

@st.cache_data
def load_excel(file):
    xls = pd.ExcelFile(file)
    dfs = {}
    for sheet in xls.sheet_names:
        try:
            df = xls.parse(sheet)
            df.columns = df.columns.str.strip()
            dfs[sheet] = df
        except:
            continue
    return dfs

@st.cache_resource
def train_model(df_perf, df_gmv):
    df_gmv["Data"] = pd.to_datetime(df_gmv["Data"], errors="coerce")
    df_gmv["campaign_type"] = df_gmv["Data"].apply(lambda d: "unknown" if pd.isna(d) else (
        "dday" if d.day == d.month else "midmonth" if d.day == 15 else "payday" if d.day == 25 else "normal_day"))
    df_gmv["year_month"] = df_gmv["Data"].dt.to_period("M")

    month_map = {m.upper(): i for i, m in enumerate(['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'], start=1)}
    df_perf["month_num"] = df_perf["Month"].str[:3].str.upper().map(month_map)
    df_perf["date"] = pd.to_datetime(dict(year=df_perf["Year"], month=df_perf["month_num"], day=1), errors="coerce")
    df_perf["year_month"] = df_perf["date"].dt.to_period("M")

    df = pd.merge(df_perf, df_gmv[["year_month", "campaign_type"]].drop_duplicates(), on="year_month", how="left")
    df = df.rename(columns={
        "Product": "product_name", "Brand": "brand", "Platforms": "platform",
        "Sales (Confirmed Order) (THB)": "sales_thb", "Units (Confirmed Order)": "units_sold",
        "Conversion Rate (Confirmed Order)": "conversion_rate"
    })
    df["conversion_rate"] = pd.to_numeric(df["conversion_rate"], errors="coerce")
    df["year_month"] = df["year_month"].astype(str)
    df = df.dropna(subset=["sales_thb", "brand", "product_name", "platform", "campaign_type"])
    df["month_numeric"] = df["year_month"].apply(lambda x: int(x.replace("-", "")))

    growth_rates = df.groupby(["product_name", "platform"]).apply(
        lambda g: g.sort_values("month_numeric").assign(
            pct_change=g["sales_thb"].pct_change().fillna(0)
        )["pct_change"].mean()
    ).reset_index(name="avg_growth_rate")

    summary = df.groupby(["brand", "product_name", "platform", "year_month", "campaign_type"]).agg({
        "sales_thb": "sum", "units_sold": "sum", "conversion_rate": "mean"
    }).reset_index()
    summary = pd.merge(summary, growth_rates, on=["product_name", "platform"], how="left").fillna(0)

    le_brand, le_product, le_platform, le_campaign = LabelEncoder(), LabelEncoder(), LabelEncoder(), LabelEncoder()
    summary["month_enc"] = summary["year_month"].apply(lambda x: int(x.replace("-", "")))
    summary["brand_enc"] = le_brand.fit_transform(summary["brand"])
    summary["product_enc"] = le_product.fit_transform(summary["product_name"])
    summary["platform_enc"] = le_platform.fit_transform(summary["platform"])
    summary["campaign_enc"] = le_campaign.fit_transform(summary["campaign_type"])

    X = summary[["brand_enc", "product_enc", "platform_enc", "campaign_enc", "month_enc", "avg_growth_rate"]]
    y = summary["sales_thb"]
    X = X.replace([np.inf, -np.inf], np.nan).dropna()
    y = y[X.index]

    model = GradientBoostingRegressor(n_estimators=300, learning_rate=0.1, max_depth=6)
    model.fit(X, y)

    encoders = {"brand": le_brand, "product": le_product, "platform": le_platform, "campaign": le_campaign}
    return model, summary, encoders

def forecast_future(summary, model, encoders, months_ahead, growth_expectation=1.0):
    future_dates = pd.date_range(datetime.today(), periods=months_ahead, freq="MS").to_period("M").astype(str)
    base = summary[["brand", "product_name", "platform", "campaign_type"]].drop_duplicates()

    rows = []
    for month in future_dates:
        for _, row in base.iterrows():
            rows.append({
                "brand": row["brand"],
                "product_name": row["product_name"],
                "platform": row["platform"],
                "campaign_type": row["campaign_type"],
                "year_month": month
            })

    future = pd.DataFrame(rows)
    future["brand_enc"] = encoders["brand"].transform(future["brand"])
    future["product_enc"] = encoders["product"].transform(future["product_name"])
    future["platform_enc"] = encoders["platform"].transform(future["platform"])
    future["campaign_enc"] = encoders["campaign"].transform(future["campaign_type"])
    future["month_enc"] = future["year_month"].apply(lambda x: int(x.replace("-", "")))

    growth_lookup = summary.groupby(["product_name", "platform"])["avg_growth_rate"].mean().reset_index()
    future = pd.merge(future, growth_lookup, on=["product_name", "platform"], how="left")
    future["avg_growth_rate"] = future["avg_growth_rate"].fillna(0) * growth_expectation

    X = future[["brand_enc", "product_enc", "platform_enc", "campaign_enc", "month_enc", "avg_growth_rate"]]
    future["forecast_sales"] = model.predict(X)

    return future

def generate_ai_insight(df_top):
    prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏Ç‡∏≤‡∏¢‡∏î‡∏µ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ:

{df_top.to_string(index=False)}

‡πÇ‡∏õ‡∏£‡∏î‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡πÑ‡∏°‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ‡∏ñ‡∏∂‡∏á‡∏Ç‡∏≤‡∏¢‡∏î‡∏µ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏£‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ï‡∏ä‡πà‡∏ß‡∏á‡πÑ‡∏´‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
"""
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ï"},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

# === UI ===
st.title("üß† AI Sales & Product Forecasting Dashboard")
uploaded_file = st.sidebar.file_uploader("üìÇ Upload Excel File", type=["xlsx"])
months_to_predict = st.sidebar.slider("üîÆ Forecast Months Ahead", 1, 60, 3)

if uploaded_file:
    dfs = load_excel(uploaded_file)
    perf_sheet = next((k for k in dfs if "Perf" in k or "Performance" in k), None)
    gmv_sheet = next((k for k in dfs if "GMV" in k), None)

    if perf_sheet and gmv_sheet:
        df_perf = dfs[perf_sheet]
        df_gmv = dfs[gmv_sheet]
        model, summary, encoders = train_model(df_perf, df_gmv)
        df_future = forecast_future(summary, model, encoders, months_to_predict)

        platform = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Platform", ["All"] + sorted(df_future["platform"].unique()))
        if platform != "All":
            df_future = df_future[df_future["platform"] == platform]

        col1, col2, col3 = st.columns(3)
        col1.metric("üí∞ Forecasted Sales", f"{df_future['forecast_sales'].sum():,.0f} THB")
        col2.metric("üì¶ Total SKUs", f"{df_future['product_name'].nunique()}")
        col3.metric("üìà Avg. Sales/SKU", f"{df_future['forecast_sales'].mean():,.2f} THB")

        st.subheader("üìà Forecasted Sales Trend")
        trend = df_future.groupby("year_month")["forecast_sales"].sum().reset_index()
        st.plotly_chart(px.line(trend, x="year_month", y="forecast_sales", markers=True), use_container_width=True)

        st.subheader("üèÜ Top Forecasted Products")
        top_products = df_future.groupby("product_name")["forecast_sales"].sum().sort_values(ascending=False).head(10).reset_index()
        st.plotly_chart(px.bar(top_products, x="forecast_sales", y="product_name", orientation="h"), use_container_width=True)

        st.subheader("üìä Forecasted Sales by Platform")
        pie_data = df_future.groupby("platform")["forecast_sales"].sum().reset_index()
        st.plotly_chart(px.pie(pie_data, names="platform", values="forecast_sales", hole=0.3), use_container_width=True)

        st.subheader("üí° AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå & ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ï")
        st.info(generate_ai_insight(top_products))

        st.subheader("üìÑ Forecast Table")
        st.dataframe(df_future, use_container_width=True)
    else:
        st.warning("‚ùó ‡πÑ‡∏°‡πà‡∏û‡∏ö Sheet ‡∏ó‡∏µ‡πà‡∏ä‡∏∑‡πà‡∏≠ Performance ‡∏´‡∏£‡∏∑‡∏≠ GMV")
else:
    st.info("üì§ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel")
